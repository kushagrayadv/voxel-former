{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xAjGM6XyST3"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9P9CXUUs_7a"
      },
      "outputs": [],
      "source": [
        "def generate_sbatch_fmri(\n",
        "    job_name=\"brainnat\",\n",
        "    hour=48,\n",
        "    minute=00,\n",
        "    constraint=\"a100|h100\",\n",
        "    overlay_ext3=None,\n",
        "    output_dir_base=\"./jobs/\",\n",
        "    script_name=\"Train.py\",\n",
        "    num_gpus=1,\n",
        "    batch_size=4,\n",
        "    singularity_path=\"/scratch/work/public/singularity/cuda12.6.2-cudnn9.5.0-devel-ubuntu24.04.1.sif\",\n",
        "    project_dir=\"/scratch/ky2684/brain-decoding/Brain_Decoding/Downstream\",\n",
        "    use_env_var=False,\n",
        "    env_file_path=\"/scratch/ky2684/brain-decoding/Brain_Decoding/.env\",\n",
        "    ssl_cert_file_path=\"/scratch/ky2684/brain-decoding/Brain_Decoding/tmp/cacert.pem\",\n",
        "    params=None,\n",
        "):\n",
        "\n",
        "    if params is None or not overlay_ext3:\n",
        "        raise ValueError(\"Params cannot be None\")\n",
        "\n",
        "    if use_env_var and not env_file_path:\n",
        "        raise ValueError(\"env file path not present\")\n",
        "\n",
        "    # Add current date to job name\n",
        "    current_date = datetime.now().strftime(\"%Y%m%d\")\n",
        "    job_name = f\"{job_name}_{current_date}\"\n",
        "\n",
        "    # Start constructing the sbatch script\n",
        "    text = \"#!/bin/bash\\n\\n\"\n",
        "    text += f\"#SBATCH --job-name={job_name}\\n\"\n",
        "    text += \"#SBATCH --nodes=1\\n\"\n",
        "    text += \"#SBATCH --cpus-per-task=16\\n\"\n",
        "    text += \"#SBATCH --mem=64GB\\n\"\n",
        "    text += f\"#SBATCH --time={hour}:{minute:02d}:00\\n\"\n",
        "    text += f\"#SBATCH --gres=gpu:{num_gpus}\\n\"\n",
        "    text += f'#SBATCH --constraint=\"{constraint}\"\\n'\n",
        "    text += \"#SBATCH --account=pr_60_tandon_advanced\\n\"\n",
        "    text += \"#SBATCH --output=./slurm-logs/%x-%j.out\\n\"\n",
        "    text += \"#SBATCH --error=./slurm-logs/%x-%j.err\\n\\n\"\n",
        "\n",
        "    text += f\"overlay_ext3={overlay_ext3}\\n\"\n",
        "    text += f\"export NUM_GPUS={num_gpus}  # Set to equal gres=gpu:#!\\n\"\n",
        "    text += f\"export BATCH_SIZE={batch_size} # 21 for multisubject / 24 for singlesubject (orig. paper used 42 for multisubject / 24 for singlesubject)\\n\"\n",
        "    text += \"export GLOBAL_BATCH_SIZE=$((BATCH_SIZE * NUM_GPUS))\\n\\n\"\n",
        "\n",
        "    text += \"# Make sure another job doesnt use same port, here using random number\\n\"\n",
        "    text += \"export MASTER_PORT=$((RANDOM % (19000 - 11000 + 1) + 11000))\\n\"\n",
        "    text += 'export HOSTNAMES=$(scontrol show hostnames \"$SLURM_JOB_NODELIST\")\\n'\n",
        "    text += 'export MASTER_ADDR=$(scontrol show hostnames \"$SLURM_JOB_NODELIST\" | head -n 1)\\n'\n",
        "    text += (\n",
        "        'export COUNT_NODE=$(scontrol show hostnames \"$SLURM_JOB_NODELIST\" | wc -l)\\n'\n",
        "    )\n",
        "    text += \"echo MASTER_ADDR=${MASTER_ADDR}\\n\"\n",
        "    text += \"echo MASTER_PORT=${MASTER_PORT}\\n\"\n",
        "    text += \"echo WORLD_SIZE=${COUNT_NODE}\\n\\n\"\n",
        "\n",
        "    text += \"singularity exec --nv \\\\\\n\"\n",
        "    text += \"    --overlay ${overlay_ext3}:ro \\\\\\n\"\n",
        "    text += f\"    {singularity_path} \\\\\\n\"\n",
        "    text += '    /bin/bash -c \"\\n'\n",
        "    text += \"source /ext3/env.sh\\n\"\n",
        "    text += f\"export $(grep -v '^#' {env_file_path} | xargs)\\n\" if use_env_var else \"\"\n",
        "    text += f\"cd {project_dir}\\n\\n\"\n",
        "\n",
        "    text += f\"export SSL_CERT_FILE={ssl_cert_file_path}\\n\"\n",
        "    text += \"accelerate launch --num_processes=${NUM_GPUS} --main_process_port=${MASTER_PORT} --mixed_precision=fp16 Train.py\\\\\\n\"\n",
        "\n",
        "    for param_level in params.keys():\n",
        "        for name, value in params[param_level].items():\n",
        "            if param_level == \"base\":\n",
        "                text += f\"    {name}={value} \\\\\\n\"\n",
        "            else:\n",
        "                text += f\"    {param_level}.{name}={value} \\\\\\n\"\n",
        "\n",
        "    text += '\"\\n'\n",
        "\n",
        "    # Save the sbatch script to a file\n",
        "    os.makedirs(output_dir_base, exist_ok=True)\n",
        "    job_file = os.path.join(output_dir_base, f\"{job_name}.sbatch\")\n",
        "    with open(job_file, \"w\") as f:\n",
        "        f.write(text)\n",
        "    print(f\"sbatch {job_file}\")\n",
        "    return text\n",
        "\n",
        "\n",
        "def generate_ablation_jobs(base_params, param_ranges, job_params):\n",
        "    jobs = []\n",
        "\n",
        "    # Generate all combinations of parameter values\n",
        "    param_names = list(param_ranges.keys())\n",
        "    param_values = list(param_ranges.values())\n",
        "    model_name_param = base_params[\"base\"][\"model_name\"]\n",
        "    for values in itertools.product(*param_values):\n",
        "        params = base_params.copy()\n",
        "\n",
        "        for name, value in zip(param_names, values):\n",
        "            for param_level in params.keys():\n",
        "                if name in params[param_level]:\n",
        "                    params[param_level][name] = value\n",
        "\n",
        "        # Generate a unique job name\n",
        "        model_name = f\"{model_name_param}_{'_'.join([f'{name}_{value}' for name, value in zip(param_names, values)])}\"\n",
        "        model_name = model_name + \"_single\" if job_params[\"num_gpus\"] == 1 else model_name\n",
        "        params[\"base\"][\"model_name\"] = (\n",
        "            model_name + f\"_{datetime.now().strftime('%Y%m%d')}\"\n",
        "        )\n",
        "        job_name = f\"{params['base']['wandb_project']}_{model_name}\"\n",
        "        \n",
        "        # Generate the job script\n",
        "        job_params['batch_size'] = params['train']['batch_size']\n",
        "        job_script = generate_sbatch_fmri(\n",
        "            job_name=job_name,\n",
        "            params=params,\n",
        "            **job_params,\n",
        "        )\n",
        "\n",
        "        jobs.append((job_name, job_script))\n",
        "\n",
        "    return jobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRU8RuVis_7d",
        "outputId": "20685ed2-4f79-4239-ad44-33f19ba41b74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sbatch ./jobs/fmri_new_max_lr_5e-05_encoder_hidden_dim_32_decoder_hidden_dim_256_progressive_dims_True_dim_scale_factor_2_20250323.sbatch\n",
            "sbatch ./jobs/fmri_new_max_lr_5e-05_encoder_hidden_dim_32_decoder_hidden_dim_256_progressive_dims_True_dim_scale_factor_4_20250323.sbatch\n",
            "sbatch ./jobs/fmri_new_max_lr_5e-05_encoder_hidden_dim_32_decoder_hidden_dim_512_progressive_dims_True_dim_scale_factor_2_20250323.sbatch\n",
            "sbatch ./jobs/fmri_new_max_lr_5e-05_encoder_hidden_dim_32_decoder_hidden_dim_512_progressive_dims_True_dim_scale_factor_4_20250323.sbatch\n"
          ]
        }
      ],
      "source": [
        "default_params = {\n",
        "    \"base\": {\n",
        "        \"wandb_log\": True,\n",
        "        \"wandb_project\": \"fmri_new\",\n",
        "        \"wandb_entity\": \"nyu_brain_decoding\",\n",
        "        \"model_name\": \"perceiver_grad_clip\",\n",
        "    },\n",
        "    \"data\": {\n",
        "        \"data_path\": \"/scratch/cl6707/Shared_Datasets/NSD_MindEye/Mindeye2\",\n",
        "        \"cache_dir\": \"/scratch/cl6707/Shared_Datasets/NSD_MindEye/Mindeye2\",\n",
        "        \"subj\": 2,\n",
        "        \"num_sessions\": 40,\n",
        "        \"multi_subject\": \"'[2, 3, 4, 5, 6, 7, 8]'\",\n",
        "        \"new_test\": True,\n",
        "    },\n",
        "    \"model\": {\n",
        "        \"encoder_type\": \"linformer\",\n",
        "        \"decoder_type\": \"perceiver\",  # Options: 'qformer', 'perceiver'\n",
        "        \"n_blocks\": 4,\n",
        "        \"decoder_hidden_dim\": 1280,\n",
        "        \"encoder_hidden_dim\": 256,\n",
        "        \"use_mixer\": False,\n",
        "        \"num_heads\": 8,\n",
        "        \"head_dim\": 64,  # New parameter for Perceiver\n",
        "        \"self_per_cross_attn\": 1,  # New parameter for Perceiver\n",
        "        \"tome_r\": 1000,\n",
        "        \"last_n_features\": 16,\n",
        "        \"nat_depth\": 8,\n",
        "        \"nat_num_neighbors\": 8,\n",
        "        \"full_attention\": True,\n",
        "        \"n_blocks_decoder\": 6,\n",
        "        \"drop\": 0.1,\n",
        "        \"progressive_dims\": True,\n",
        "        \"initial_tokens\": 15000,\n",
        "        \"dim_scale_factor\": 0,\n",
        "        \"clip_seq_dim\": 256,\n",
        "        \"clip_emb_dim\": 1664,\n",
        "    },\n",
        "    \"train\": {\n",
        "        \"use_prior\": True,\n",
        "        \"blurry_recon\": False,\n",
        "        \"batch_size\": 8,\n",
        "        \"global_batch_size\": None,\n",
        "        \"num_epochs\": 150,\n",
        "        \"seed\": 42,\n",
        "        \"max_lr\": 5.0e-05,\n",
        "        \"lr_scheduler_type\": \"cycle\",\n",
        "        \"ckpt_saving\": True,\n",
        "        \"ckpt_interval\": 3,\n",
        "        \"ckpt_iter\": 15000,\n",
        "        \"mixup_pct\": 0.33,\n",
        "        \"use_image_aug\": False,\n",
        "        \"clip_scale\": 1.0,  # base task\n",
        "        \"blur_scale\": 0.5,  # only applies when model.blurry_recon is True\n",
        "        \"prior_scale\": 30,  # only applies when model.use_prior is True\n",
        "        \"multisubject_ckpt\": None,\n",
        "    },\n",
        "}\n",
        "\n",
        "param_ranges = {\"batch_size\": [16], \"num_epochs\": [100]}\n",
        "\n",
        "job_params = {\n",
        "    \"hour\": 24,\n",
        "    \"minute\": 00,\n",
        "    \"constraint\": \"h100|a100\",\n",
        "    \"num_gpus\": 2,\n",
        "    \"batch_size\": default_params[\"train\"][\"batch_size\"],\n",
        "    \"overlay_ext3\": \"/scratch/ky2684/brain-decoding/fmri-img-reconstruct.ext3\",\n",
        "    \"singularity_path\": \"/scratch/work/public/singularity/cuda12.6.2-cudnn9.5.0-devel-ubuntu24.04.1.sif\",\n",
        "    \"project_dir\": \"/scratch/ky2684/brain-decoding/Brain_Decoding/Downstream\",\n",
        "    \"use_env_var\": True,\n",
        "    \"env_file_path\": \"/scratch/ky2684/brain-decoding/Brain_Decoding/.env\",\n",
        "    \"ssl_cert_file_path\": \"/scratch/ky2684/brain-decoding/Brain_Decoding/tmp/cacert.pem\",\n",
        "}\n",
        "\n",
        "generate_ablation_jobs(default_params, param_ranges, job_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPITs_WRE9q-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "2.7.undefined"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
