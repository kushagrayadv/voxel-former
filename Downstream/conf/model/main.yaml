# ------------------------------------------------------------------------------
# Model-related hyperparameters and configurations
# ------------------------------------------------------------------------------

# Encoder type (Used with qformer decoder)
encoder_type: 'tomer'

# Decoder type
decoder_type: 'qformer'  # Options: 'qformer', 'perceiver'

# Perceiver variant type
perceiver_type: 'variable'  # Options: 'original', 'hierarchical', 'variable'

# Architecture hyperparams
n_blocks: 4
decoder_hidden_dim: 1280
encoder_hidden_dim: 256
encoder_seq_len: 2048 # New parameter for linformer
share_kv: False # New parameter for linformer
use_mixer: false
num_heads: 8
head_dim: 64  # New parameter for Perceiver
self_per_cross_attn: 1  # New parameter for Perceiver
use_avg_pool: false   # New parameter for Perceiver
mlp_clip_head: false
tome_r: 1000
last_n_features: 16
nat_depth: 8
nat_num_neighbors: 8
full_attention: true
n_blocks_decoder: 10

# Hierarchical Perceiver parameters
downsample_factors: [2, 2, 2, 2]  # Controls token reduction at each level
use_residual: false               # Use U-Net style skip connections
downsample_method: "grid"         # Downsampling method: "grid" or "knn"
visualize_hierarchy: true         # Visualize hierarchical downsampling

# Varible Perceiver params
variable_hidden_dims: [128, 185, 266, 384, 554, 800, 1154, 1664]
use_siren_emb: true

# Dropout and progressive-dim scaling
drop: 0.1
progressive_dims: true
initial_tokens: 15000
dim_scale_factor: 0

# output
clip_seq_dim: 256
clip_emb_dim: 1664